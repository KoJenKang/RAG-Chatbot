# Trends Marketplace Project
In this project, we leveraged the Retrieval-Augmented Generation (RAG) approach to build a chatbot for the Carlson School's website, using Gemini, a large language model developed by Google. This project showcases the benefits of RAG compared to traditional generative AI systems and explores its business applications.
 
# What is RAG?
RAG combines the power of retrieval-based methods with generative AI to provide more accurate, real-time responses by grounding outputs in external, validated data sources.

### RAG vs. Traditional Generative AI

| **Feature**            | **Traditional AI**                | **RAG**                                      |
|-------------------------|------------------------------------|---------------------------------------------|
| **Data Source**         | Static, pre-trained knowledge     | Dynamic, real-time retrieval                |
| **Accuracy**            | Prone to hallucinations           | Grounded and factually accurate             |
| **Update Frequency**    | Requires retraining for updates   | Instantly retrieves the latest information  |
| **Scalability**         | Limited without costly retraining | Easily scales with external data            |

# How we did this?


# Code & files
To run the code, upload the data files from a folder named "data" in the Colab environment and set up the necessary key.

This version currently includes only the undergraduate data. Graduate data will be added later this week.

At this stage, the Gemini embedding function successfully converts text into vectors and stores the vector data in ChromaDB. After testing several queries, the database returned reasonable chunks, and the LLM (Gemini) provided appropriate responses.

ðŸ“Œ[Colab](https://colab.research.google.com/drive/1_TYG8saveyjD1yY4RKJRxZfFySosIW6Q#scrollTo=sP_iDUhPOd2k)
